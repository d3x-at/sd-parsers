"""Parser for images generated by ComfyUI or similar."""

import json
import logging
from collections import defaultdict
from contextlib import suppress
from typing import Any, Callable, Dict, Generator, List, Optional, Set, Tuple

from PIL.Image import Image

from sd_parsers.data import Generators, Model, Prompt, Sampler
from sd_parsers.exceptions import MetadataError, ParserError
from sd_parsers.parser import Parser, ParseResult, ReplacementRules

logger = logging.getLogger(__name__)

SAMPLER_PARAMS = {"sampler_name", "steps", "cfg"}
REPLACEMENT_RULES: ReplacementRules = [("cfg", "cfg_scale")]

POSITIVE_PROMPT_KEYS = ["text", "positive"]
NEGATIVE_PROMPT_KEYS = ["text", "negative"]
IGNORE_LINK_TYPES_PROMPT = ["CLIP"]
IGNORE_CLASS_TYPES = ["ConditioningCombine"]


class ComfyUIParser(Parser):
    """Parser for images generated by ComfyUI"""

    _generator = Generators.COMFYUI

    def read_parameters(
        self,
        image: Image,
        get_metadata: Optional[Callable[[Image, Generators], Dict[str, Any]]] = None,
    ):
        if image.format != "PNG":
            raise MetadataError("unsupported image format", image.format)

        try:
            metadata = get_metadata(image, self._generator) if get_metadata else image.info
            prompt = metadata["prompt"]
            workflow = metadata["workflow"]
            parameters = {"prompt": json.loads(prompt), "workflow": json.loads(workflow)}
        except Exception as error:
            raise MetadataError("no matching metadata") from error

        return parameters, None

    def parse(self, parameters: Dict[str, Any], _) -> ParseResult:
        try:
            prompt = parameters["prompt"]
            workflow = parameters["workflow"]
        except KeyError as error:
            raise ParserError("error reading parameters") from error

        samplers, metadata = ImageContext.extract(self, prompt, workflow)
        return self._generator, samplers, metadata


class ImageContext:
    parser: ComfyUIParser
    prompt: Dict[int, Any]
    links: Dict[int, Dict[int, Set[str]]]
    processed_nodes: Set[int]

    def __init__(self, parser: ComfyUIParser, prompt, workflow):
        self.parser = parser
        self.processed_nodes = set()

        # ensure that prompt keys are integers
        try:
            self.prompt = {int(k): v for k, v in prompt.items()}
        except (AttributeError, ValueError) as error:
            raise ParserError("prompt has unexpected format") from error

        # build links dictionary (dict[input_id, dict[output_id, set[link_type]]])
        self.links = defaultdict(lambda: defaultdict(set))
        try:
            for _, output_id, _, input_id, _, link_type in workflow["links"]:
                self.links[int(input_id)][int(output_id)].add(link_type)
        except (TypeError, KeyError, ValueError) as error:
            raise ParserError("workflow has unexpected format") from error

    @classmethod
    def extract(
        cls, parser: ComfyUIParser, prompt: Any, links: Any
    ) -> Tuple[List[Sampler], Dict[str, List[Dict[str, Any]]]]:
        """Extract samplers with their child parameters aswell as metadata"""
        context = cls(parser, prompt, links)
        samplers = []
        metadata = defaultdict(list)

        # Pass 1: get samplers and related data
        for node_id, node in context.prompt.items():
            sampler = context._try_get_sampler(node_id, node)
            if sampler:
                samplers.append(sampler)

        # Pass 2: put information from unprocessed nodes into metadata
        for node_id, node in context.prompt.items():
            if node_id in context.processed_nodes:
                continue

            with suppress(KeyError):
                inputs = context._get_input_values(node["inputs"], node_id)
                if inputs:
                    metadata[node["class_type"]].append(inputs)

        return samplers, dict(metadata)

    def _try_get_sampler(self, node_id: int, node):
        """Test if this node could contain sampler data"""
        try:
            inputs = dict(node["inputs"])
            if not SAMPLER_PARAMS.issubset(inputs.keys()):
                return None
        except (KeyError, TypeError):
            return None

        logger.debug("found sampler #%d", node_id)
        self.processed_nodes.add(node_id)

        # Sampler parameters
        sampler_name = inputs.pop("sampler_name")
        sampler_parameters = self.parser.normalize_parameters(
            self._get_input_values(inputs), REPLACEMENT_RULES
        )

        # Sampler
        sampler = {
            "sampler_id": node_id,
            "name": sampler_name,
            "parameters": sampler_parameters,
        }

        # Model
        with suppress(KeyError, ValueError):
            model_id = int(inputs["model"][0])
            sampler["model"] = self._get_model(model_id)

        # Prompt
        with suppress(KeyError, ValueError):
            positive_prompt_id = int(inputs["positive"][0])
            sampler["prompts"] = self._get_prompts(
                positive_prompt_id,
                POSITIVE_PROMPT_KEYS,
            )

        # Negative Prompt
        with suppress(KeyError, ValueError):
            negative_prompt_id = int(inputs["negative"][0])
            sampler["negative_prompts"] = self._get_prompts(
                negative_prompt_id,
                NEGATIVE_PROMPT_KEYS,
            )

        return Sampler(**sampler)

    def _get_model(self, initial_node_id: int) -> Optional[Model]:
        """Get the first model reached from the given node_id"""
        logger.debug("looking for model: #%s", initial_node_id)

        for node_id, node, trace in self._traverse(initial_node_id):
            try:
                inputs = dict(node["inputs"])
                ckpt_name = inputs.pop("ckpt_name")
            except KeyError:
                pass
            else:
                self.processed_nodes.add(node_id)
                logger.debug("found model #%d: %s", node_id, ckpt_name)

                metadata = self._get_input_values(inputs)
                metadata.update(self._get_trace_metadata(trace))

                model = Model(model_id=node_id, name=ckpt_name, metadata=metadata)
                return model

        return None

    def _get_prompts(self, initial_node_id: int, text_keys: List[str]) -> List[Prompt]:
        """Get all prompts reachable from a given node_id."""
        logger.debug("looking for prompts: %d", initial_node_id)

        prompts = []

        def check_inputs(node_id: int, inputs: Dict, trace: List[int]) -> bool:
            found_prompt = False
            for key in text_keys:
                try:
                    text = inputs.pop(key)
                except KeyError:
                    continue

                if isinstance(text, str):
                    logger.debug("found prompt %s#%d: %s", key, node_id, text)

                    metadata = self._get_input_values(inputs)
                    metadata.update(self._get_trace_metadata(trace))

                    prompts.append(
                        Prompt(
                            value=text.strip(),
                            prompt_id=node_id,
                            metadata=metadata,
                        )
                    )
                    found_prompt = True

            if found_prompt:
                self.processed_nodes.update([node_id], trace)
                return False
            return True

        prompt_iterator = self._traverse(initial_node_id, IGNORE_LINK_TYPES_PROMPT)
        with suppress(StopIteration):
            node_id, node, trace = next(prompt_iterator)
            while True:
                recurse = True
                try:
                    inputs = node["inputs"]
                except KeyError:
                    pass
                else:
                    recurse = check_inputs(node_id, dict(inputs), trace)

                node_id, node, trace = prompt_iterator.send(recurse)

        return prompts

    def _traverse(
        self, node_id: int, ignored_link_types: Optional[List[str]] = None
    ) -> Generator[Tuple[int, Any, List[int]], Optional[bool], None]:
        """Traverse backwards through node tree, starting at a given node_id"""
        visited = set()
        ignore_links = set(ignored_link_types) if ignored_link_types else set()

        def traverse_inner(node_id: int, trace: List[int]):
            visited.add(node_id)

            with suppress(KeyError):
                recurse = yield node_id, self.prompt[node_id], trace[:-1]
                if recurse is False:
                    return

            with suppress(KeyError, RecursionError):
                for link_id, link_types in self.links[node_id].items():
                    if link_id not in visited and link_types - ignore_links:
                        logger.debug("%d->%d, %s%s", node_id, link_id, "." * len(trace), link_types)
                        yield from traverse_inner(link_id, trace + [link_id])

        yield from traverse_inner(node_id, [node_id])

    def _get_trace_metadata(self, trace: List[int]):
        metadata = {}

        for node_id in trace:
            try:
                node = self.prompt[node_id]
                class_type = node["class_type"]

                if class_type in IGNORE_CLASS_TYPES:
                    continue

                value = self._get_input_values(node["inputs"], node_id)

            except KeyError:
                continue

            try:
                entry = metadata[class_type]
                if isinstance(entry, list):
                    entry.append(value)
                else:
                    metadata[class_type] = [entry, value]
            except KeyError:
                metadata[class_type] = value

        return metadata

    def _get_input_values(
        self,
        inputs: Dict[str, Any],
        node_id: Optional[int] = None,
    ) -> Dict[str, Any]:
        with suppress(Exception):
            vals = {key: value for key, value in inputs.items() if not isinstance(value, list)}
            if vals:
                return vals if node_id is None else {"id": node_id, **vals}
        return {}
