"""Parser for images generated by InvokeAI."""
from __future__ import annotations

import copy
import json
import re
from contextlib import suppress
from enum import Enum
from typing import Any, Callable, Dict, List, NamedTuple

from PIL.Image import Image

from .._models import Model, Prompt, Sampler
from .._parser import Generators, Parser, ParseResult, ReplacementRules, pop_keys
from .._prompt_info import PromptInfo
from ..exceptions import ParserError

SAMPLER_PARAMS = ["cfg_scale", "cfg_rescale_multiplier", "perlin", "seed", "steps", "threshold"]

REPLACEMENT_RULES: ReplacementRules = [("size", (["width", "height"], "{width}x{height}"))]

DREAM_KEYS = {
    "A": ("sampler", None),
    "C": ("cfg_scale", float),
    "H": ("height", int),
    "s": ("steps", int),
    "S": ("seed", int),
    "W": ("width", int),
}

RE_PROMPT_NEGATIVES = re.compile(r"\[([^\[]*)\]")


class InvokeVariant(str, Enum):
    """InvokeAI metadata variants"""

    IMETA = "invokeai_metadata"
    SDMETA = "sd-metadata"
    DREAM = "Dream"


class InvokeAIParser(Parser):
    """parser for images generated by invokeai"""

    @property
    def generator(self):
        return Generators.INVOKEAI

    def read_parameters(self, image: Image, use_text: bool = True):
        if image.format != "PNG":
            return None

        image_info = image.text if use_text else image.info  # type: ignore
        for variant in InvokeVariant:
            try:
                metadata = image_info[variant.value]
            except KeyError:
                continue

            if VARIANT_PARSERS[variant].decode_json:
                try:
                    metadata = json.loads(metadata)
                except (TypeError, json.JSONDecodeError) as error:
                    raise ParserError("error reading metadata") from error

            return PromptInfo(
                self,
                parameters={variant.value: metadata},
                _parsing_context=variant,
            )

        return None

    def parse(self, parameters: Dict[str, Any], parsing_context: InvokeVariant) -> ParseResult:
        try:
            metadata = copy.deepcopy(parameters[parsing_context.value])
        except KeyError as error:
            raise ParserError("error reading parameter string") from error

        samplers, metadata = VARIANT_PARSERS[parsing_context].parse(self, metadata)

        return samplers, metadata


def _parse_invokeai_meta(parser: Parser, metadata: Dict[str, Any]):
    """Read generation parameters from the newest InvokeAI metadata format."""

    # sampler
    sampler = _get_sampler(parser, metadata, "scheduler")

    # positive prompt
    with suppress(KeyError):
        sampler["prompts"] = [Prompt(value=metadata.pop("positive_prompt"))]

    # negative prompt
    with suppress(KeyError):
        sampler["negative_prompts"] = [Prompt(value=metadata.pop("negative_prompt"))]

    # model
    with suppress(KeyError):
        model_info = metadata.pop("model")

        sampler["model"] = Model(
            name=model_info.pop("model_name"),
            parameters=model_info,
        )

    return [Sampler(**sampler)], parser.normalize_parameters(metadata, REPLACEMENT_RULES, False)


def _parse_sd_metadata(parser: Parser, metadata: Dict[str, Any]):
    """Read generation parameters for an image containing a `sd-metadata` field."""

    try:
        metadata_image = metadata.pop("image")
    except KeyError as error:
        raise ParserError("no image entry found") from error

    # sampler
    sampler = _get_sampler(parser, metadata_image, "sampler")

    # prompts
    try:
        prompts = metadata_image.pop("prompt")
    except KeyError as error:
        raise ParserError("no prompt entry found") from error
    except AttributeError as error:
        raise ParserError("malformed prompt information") from error

    for prompt_item in prompts:
        try:
            prompt_text = prompt_item.pop("prompt")
            _add_prompts(sampler, prompt_text, prompt_item)
        except KeyError:
            continue
        except AttributeError as error:
            raise ParserError("malformed prompt information") from error

    # model
    model_name = metadata.pop("model_weights", None)
    model_hash = metadata.pop("model_hash", None)
    if model_name or model_hash:
        sampler["model"] = Model(name=model_name, model_hash=model_hash)

    metadata = parser.normalize_parameters({**metadata, **metadata_image}, REPLACEMENT_RULES)

    return [Sampler(**sampler)], metadata


def _parse_dream(parser: Parser, _metadata: str):
    """Read generation parameters from images generated by legacy InvokeAI."""

    match = re.match(r'^"(.*?)"(.*)$', _metadata)
    if match is None:
        raise ParserError("could not read generation parameters")

    prompts, args = match.groups()

    # split args into metadata
    metadata = {}
    end = 0
    for match in re.finditer(r"\s+-(\w+)\s+([^\s]+)", args):
        key, value = match.groups()

        try:
            key_name, convert = DREAM_KEYS[key]
            metadata[key_name] = convert(value) if convert else value
        except (KeyError, ValueError):
            metadata[key] = value

        end = match.end(0)

    _ = args[end:].strip()  # TODO: decide what to do with the remainder data

    # sampler
    sampler = _get_sampler(parser, metadata, "sampler")

    # prompts
    _add_prompts(sampler, prompts, {})

    return [Sampler(**sampler)], parser.normalize_parameters(metadata, REPLACEMENT_RULES, False)


def _get_sampler(parser: Parser, metadata: Dict[str, Any], key: str):
    try:
        sampler_data = {
            "name": metadata.pop(key),
            "parameters": parser.normalize_parameters(
                pop_keys(SAMPLER_PARAMS, metadata), REPLACEMENT_RULES
            ),
        }
    except KeyError as error:
        raise ParserError("no sampler found") from error

    return sampler_data


def _add_prompts(sampler: dict, combined_prompt: str, parameters: dict):
    prompts = []
    negative_prompts = []

    def _get_prompt(prompt_string: str):
        prompt_text = prompt_string.strip(" ,")
        if not prompt_text:
            raise ValueError
        return Prompt(value=prompt_text, parameters=parameters)

    prompt_index = 0
    for match in RE_PROMPT_NEGATIVES.finditer(combined_prompt):
        with suppress(ValueError):
            negative_prompts.append(_get_prompt(match.group()[1:-1]))

        start, end = match.span()
        with suppress(ValueError):
            prompts.append(_get_prompt(combined_prompt[prompt_index:start]))
        prompt_index = end

    if prompt_index < len(combined_prompt):
        with suppress(ValueError):
            prompts.append(_get_prompt(combined_prompt[prompt_index:]))

    try:
        sampler["prompts"].extend(prompts)
    except KeyError:
        sampler["prompts"] = prompts

    try:
        sampler["negative_prompts"].extend(negative_prompts)
    except KeyError:
        sampler["negative_prompts"] = negative_prompts


class VariantParser(NamedTuple):
    """Holds a parsing function for a metadata format and
    information on how to prepare the data passed to it."""

    parse: Callable[[Parser, Any], tuple[List[Sampler], Dict[str, Any]]]
    decode_json: bool


VARIANT_PARSERS = {
    InvokeVariant.SDMETA: VariantParser(_parse_sd_metadata, True),
    InvokeVariant.IMETA: VariantParser(_parse_invokeai_meta, True),
    InvokeVariant.DREAM: VariantParser(_parse_dream, False),
}
