"""Parser for images generated by InvokeAI."""
from __future__ import annotations

import json
import re
from contextlib import suppress
from enum import Enum
from typing import Any, Dict

from PIL.Image import Image
from PIL.PngImagePlugin import PngImageFile

from .._models import Model, Prompt, Sampler
from .._parser import Generators, Parser, ParseResult, ReplacementRules, pop_keys
from .._prompt_info import PromptInfo
from ..exceptions import ParserError
from ._managed_parsers import MANAGED_PARSERS

SAMPLER_PARAMS = ["cfg_scale", "cfg_rescale_multiplier", "perlin", "seed", "steps", "threshold"]

REPLACEMENT_RULES: ReplacementRules = [("size", (["width", "height"], "{width}x{height}"))]

DREAM_KEYS = {
    "A": ("sampler", None),
    "C": ("cfg_scale", float),
    "H": ("height", int),
    "s": ("steps", int),
    "S": ("seed", int),
    "W": ("width", int),
}

RE_PROMPT_NEGATIVES = re.compile(r"\[([^\[]*)\]")


class InvokeVariant(str, Enum):
    """InvokeAI metadata variants"""

    IMETA = "invokeai_metadata"
    SDMETA = "sd-metadata"
    DREAM = "Dream"


class InvokeAIParser(Parser):
    """parser for images generated by invokeai"""

    @property
    def generator(self):
        return Generators.INVOKEAI

    def read_parameters(self, image: Image):
        if not isinstance(image, PngImageFile):
            return None, None

        def get_variant():
            for variant in InvokeVariant:
                with suppress(KeyError):
                    return {"type": variant, variant.value: image.text[variant.value]}
            return None

        try:
            parameters = get_variant()
            if parameters:
                return PromptInfo(self, parameters), None

        except TypeError as error:
            return None, error

        return None, None

    def parse(self, parameters: Dict[str, Any]) -> ParseResult:
        try:
            invoke_type: InvokeVariant = parameters["type"]
            metadata = parameters[invoke_type.value]
        except KeyError as error:
            raise ParserError("error reading parameter string") from error

        try:
            samplers, metadata = VARIANT_PARSERS[invoke_type](self, metadata)
        except json.JSONDecodeError as error:
            raise ParserError("error decoding json data") from error

        return samplers or [], metadata


def _parse_invokeai_meta(parser: Parser, _metadata: str):
    """Read generation parameters from the newest InvokeAI metadata format."""
    metadata = json.loads(_metadata)

    # sampler
    sampler = _get_sampler(parser, metadata, "scheduler")

    # positive prompt
    with suppress(KeyError):
        sampler.prompts.append(Prompt(value=metadata.pop("positive_prompt")))

    # negative prompt
    with suppress(KeyError):
        sampler.negative_prompts.append(Prompt(value=metadata.pop("negative_prompt")))

    # model
    with suppress(KeyError):
        model_info = metadata.pop("model")

        sampler.model = Model(
            name=model_info.pop("model_name"),
            parameters=model_info,
        )

    return [sampler], parser.normalize_parameters(metadata, REPLACEMENT_RULES, False)


def _parse_sd_metadata(parser: Parser, _metadata: str):
    """Read generation parameters for an image containing a `sd-metadata` field."""
    metadata = json.loads(_metadata)

    try:
        metadata_image = dict(metadata.pop("image"))
    except KeyError as error:
        raise ParserError("no image entry found") from error

    # sampler
    sampler = _get_sampler(parser, metadata_image, "sampler")

    # prompts
    try:
        prompts = metadata_image.pop("prompt")
    except KeyError as error:
        raise ParserError("no prompt entry found") from error

    for prompt_item in prompts:
        prompt_weight = prompt_item.get("weight", None)
        prompt_params = {} if prompt_weight is None else {"weight": prompt_weight}
        with suppress(KeyError):
            _add_prompts(sampler, prompt_item["prompt"], prompt_params)

    # model
    model_name = metadata.pop("model_weights", None)
    model_hash = metadata.pop("model_hash", None)
    if model_name or model_hash:
        sampler.model = Model(name=model_name, model_hash=model_hash)

    metadata = parser.normalize_parameters({**metadata, **metadata_image}, REPLACEMENT_RULES)

    return [sampler], metadata


def _parse_dream(parser: Parser, _metadata: str):
    """Read generation parameters from images generated by legacy InvokeAI."""

    def get_metadata(args: str):
        end = 0
        metadata = {}
        for match in re.finditer(r"\s+-(\w+)\s+([\w\.-]+)", args):
            key, value = match.groups()

            try:
                key_name, convert = DREAM_KEYS[key]
                metadata[key_name] = value if convert is None else convert(value)
            except (KeyError, ValueError):
                metadata[key] = value

            _, end = match.span(0)

        remainder = args[end:].strip()

        return metadata, remainder

    match = re.match(r'^"(.*?)"(.*)$', _metadata)
    if match is None:
        raise ParserError("could not read generation parameters")

    prompts, args = match.groups()
    metadata, _ = get_metadata(args)  # TODO: decide what to do with the remainder data

    # sampler
    sampler = _get_sampler(parser, metadata, "sampler")

    # prompts
    _add_prompts(sampler, prompts, {})

    return [sampler], parser.normalize_parameters(metadata, REPLACEMENT_RULES, False)


def _get_sampler(parser: Parser, metadata: Dict[str, Any], key: str):
    try:
        return Sampler(
            name=metadata.pop(key),
            parameters=parser.normalize_parameters(
                pop_keys(SAMPLER_PARAMS, metadata), REPLACEMENT_RULES
            ),
        )
    except KeyError as error:
        raise ParserError("no sampler found") from error


def _add_prompts(sampler: Sampler, combined_prompt: str, parameters: dict):
    for negative_prompt in RE_PROMPT_NEGATIVES.findall(combined_prompt):
        prompt = Prompt(value=negative_prompt, parameters=parameters)
        sampler.negative_prompts.append(prompt)

    positive_prompt = RE_PROMPT_NEGATIVES.sub("", combined_prompt).strip()
    prompt = Prompt(value=positive_prompt, parameters=parameters)
    sampler.prompts.append(prompt)


VARIANT_PARSERS = {
    InvokeVariant.SDMETA: _parse_sd_metadata,
    InvokeVariant.IMETA: _parse_invokeai_meta,
    InvokeVariant.DREAM: _parse_dream,
}


MANAGED_PARSERS.append(InvokeAIParser)
